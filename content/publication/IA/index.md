---

title: "Intelligenza Artificiale"
authors:
- Diderot
- Ivana Rinaldi

date: "2020-06-24"
doi: ""
# Schedule page publish date (NOT publication's date).
publishDate: "2020-06-24"

# Summary. An optional shortened abstract.
summary: ""
tags:
- IA
- Intelligenza Artificiale
featured: true
# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: 
  focal_point: ""
  preview_only: false
# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
- internal-project
# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example

draft: false

---

**Le esigenze dietro all’Affective Computing**

Il corpo umano si fa portatore di un immenso patrimonio comunicativo da tempo oggetto di minuziosi studi e fonte di molteplici interpretazioni. 

Sarebbe possibile che un dispositivo artificioso instaurasse con esso un’interazione diretta, cogliendo e identificando le emozioni antropiche attraverso un’analisi immediata delle movenze fisiche dell’individuo, seppur per gran parte inconsce e lievemente percettibili? Verosimilmente sì. Stabilito che *“la tecnologia tende a svilupparsi prendendo a prestito strumenti teorici già disponibili al momento della sua invenzione”* avvalendosi di cospicui studi sociologici, psicologici, neurologici, matematici e informatici a riguardo, l’Intelligenza Artificiale è stata in grado di rispondere alle nuove richieste e necessità del progresso tecnologico attraverso un programma di “Affective Computing”. Ne parlò Rosalind Picard negli ultimi anni del secolo scorso: si trattava di una nuova tipologia di computazione propostasi come un moderno terreno da esplorare e da inglobare al mondo della Robotica. La ricerca sulla Programmazione Affettiva trova origine dall’esigenza di un sistema completo, efficace in qualsiasi ambito lo si voglia utilizzare e, soprattutto, intelligente – in grado perciò di provare empatia e comunicare con un essere umano come un essere umano, servendosi di segnali, stimoli fisici percepibili.

Rosalind Picard è docente al MIT, Massachusetts Institute of Technology, dove ha dato vita ad un gruppo di ricerca sul Calcolo Affettivo. Per la Picard e la sua équipe l’integrazione delle emozioni nel rapporto uomo-macchina giocava un ruolo fondamentale, come dichiarò la stessa in un’intervista per il quotidiano online “la Repubblica”: lo scopo sarebbe stato quello di associare una proprietà prettamente intrinseca dell’uomo, le emozioni, ad un computer che potesse “riconoscerle, esprimerle, comunicarle” [1998]. 
Per quale ragione una “macchina emotiva” è sostanzialmente intelligente? 

Non è più trascurabile il ruolo imperante che l’intelligenza emotiva ricopre all’interno della società, incidendo sull’attitudine di vita del singolo individuo e sulla sua presa di decisione. L’intelligenza emotiva rientra a pieno titolo tra le competenze auspicabili per un posto di lavoro. Una decisione è, dal punto di vista delle scienze cognitive, considerata “intelligente” se non conseguenza di sole inferenze logiche, bensì mossa da una percentuale emotiva che, se interamente assente, potrebbe essere ricondotta alla “Sindrome di Damasio” (Antonio Damasio, 1995). Il neurologo e neuroscienziato Antonio Damasio (Lisbona, 1944) ha introdotto e sostenuto nelle neuroscienze la valenza dello stretto collegamento tra emozione e decisione poiché, all’interno del processo deliberativo, la prima si pone come filtro per la seconda – filtro di tutela volto a preservare il benessere personale. Ad esempio, un sentore di paura potrebbe evitare noi di insinuarci in un contesto effettivamente poco chiaro, guidando la nostra scelta di evitarlo. Alla luce di ciò, negli esseri umani la Sindrome di Damasio potrebbe presentarsi come una limitazione dal punto di vista degli approcci risolutivi: gli individui affetti si ostinano, secondo Damasio, a cercare soluzioni basate esclusivamente sulla logica servendosi quindi di puro ragionamento reiterato probabilmente all’infinito, anche dopo averne verificato il fallimento. Da questi studi se ne deduce che per l’A.I. (Artificial Intelligence), volta a soddisfare sempre più i bisogni del mercato o a migliorare progressivamente la qualità della vita, il concetto è simile: è per questo che si è fatta necessaria l’introduzione della nozione di empatia associata alla macchina.

{{< figure library="true" src="IA1.png" title="" lightbox="true" >}}


**Intelligenza Artificiale Emotiva e applicazioni**

Il programma di intelligenza artificiale emotiva trova applicazione in ambito medico, dove patologie psichiche come la depressione potrebbero essere individuate dalla macchina prima ancora che dall’esame dello specialista grazie al riconoscimento di alcuni dei tratti sintomatici principali. Questo permetterebbe un’ottimizzazione del tempo e una maggiore prontezza di azione qualora fosse necessario. Nello specifico, uno studio condotto dall’Università di Vermont (Stati Uniti) ha rilevato che un sistema di intelligenza artificiale emotiva si sarebbe reso adeguato poiché, tramite gli algoritmi di apprendimento automatico o *machine learning*, sarebbe stato in grado scavare nell’interiorità di un bambino attraverso l’analisi dei suoi discorsi. I disagi infantili dovuti a situazioni di ansia e depressione sono più complessi da diagnosticare, poiché spesso non visibili e difficilmente comunicabili all’esterno; l’algoritmo è riuscito a stilare prognosi corrette l’80% delle volte e in pochi secondi, vagliando il tono della voce e la sua frequenza, le modalità d’espressione e la ripetizione di contenuti. O ancora, l’Affective Computing trova applicazione nella didattica – l’analisi delle reazioni e dell’attitudine degli studenti rispetto ai singoli argomenti di studio o modalità di erogazione dell’insegnamento può portare a risultati estremamente vantaggiosi: al docente vedrà aperta la possibilità di rinnovare e adattare il programma di insegnamento sulla base di dati certi e reali. Il ruolo della didattica a distanza non è certamente da sottovalutare; in tempi recenti gli insegnanti sono stati spinti a barcamenarsi tra le varie piattaforme online di Web Conference. Ma tenere una videochiamata a distanza con venticinque studenti (se trattasi di istruzione liceale) o con oltre duecento (se in contesto universitario) è davvero così semplice? La CMC, comunicazione mediata da Computer, risulta ancora manchevole rispetto all’insegnamento *in praesentia* e nell’era del digitale questo potrebbe risultare curioso. In effetti, gli stimoli offerti da una lezione fisicamente in aula sono difficilmente convertibili in rete, motivo per cui si è notata una scarsa motivazione all’apprendimento o nell’interazione con gli altri in un contesto di videochiamata. La realizzazione di un avatar, un volto artificiale in grado di comunicare con gli studenti basato su caratteristiche tipicamente umane potrebbe porsi a soluzione. LUCIA, così il nome della “Faccia Parlante”, è stata realizzata per riprodurre le lezioni del docente in modo espressivo ed emotivo, amplificando così l’interesse e l’interazione dei partecipanti alla lezione. 

Se l’Affective Computing non è quindi da sottovalutare nel mondo delle scienze mediche o del web learning, apportando costantemente miglioramenti non indifferenti a vantaggio del benessere sociale e culturale – che ruolo ha l’applicazione dell’A.I. nella sua “nuova” componente emozionale per le aziende? Sicuramente per chi si occupa di marketing non sono nuove le strategie mirate a colpire la sensibilità dell’utente, spingendolo così all’avvicinamento ad un determinato marchio o acquisto di uno specifico prodotto. Le aziende sanno bene che il motore delle nostre azioni sono proprio le emozioni. L’intelligenza artificiale emotiva ha quindi affinato la sua tecnica nel mondo del mercato – un esempio concreto ne è il “Kansei engineering” giapponese. Mitsuo Nagamachi, docente all’Università di Hiroshima è il fondatore di questa branca dell’ingegneria, detta anche “ingegneria affettiva”: associa le sensazioni e i bisogni del consumatore alla progettazione di un prodotto di design, adattandolo alle emozioni espresse dall’utente rendendolo “su misura”. Il metodo Kansei si basa sull’esperienza emotiva del consumatore collegandola ad una concretizzazione del prodotto da parte dell’azienda. La grande rivoluzione è che è proprio il pubblico a presentarsi non solo come protagonista, ma anche autore stesso – l’ideazione non rifletterà più il gusto del designer, bensì del fruitore. Kansei ha già ottenuto molteplici successi: possiamo citare l’esempio dell’azienda Wacoal, produttrice di lingerie per donna che, a seguito di dati raccolti riguardo un comune indumento intimo, è riuscita a concepire un nuovo modello, assicurando a Wacoal un aumento del 42% rispetto ai mercati giapponesi. 

Per quanto riguarda l’universo estremamente controverso dei Social Network è indubbio che siano già in corso indagini sull’inserimento di algoritmi di A.I. volti al monitoraggio dell’esperienza emotiva dell’utente tramite dispositivi di controllo più specifici. Si intende l’impiego di sistemi che si spingano oltre i consueti apprezzamenti in rete che ormai permettono a piattaforme quali Instagram, Facebook, Spotify, Netflix di darsi un gran da fare in quanto alla raccomandazione di contenuti; potranno però migliorare l’esposizione del loro catalogo di suggerimenti grazie a sensori di percezione del nostro stato d’animo attuale – un passo ancora superiore rispetto alle playlist personalizzate proposte da Spotify.

{{< figure library="true" src="IA2.jpg" title="" lightbox="true" >}}


**Implicazioni etiche e criticità**

Il dominio dell’Intelligenza Artificiale è dibattuto largamente su scala internazionale per via delle problematiche e implicazioni etiche che ne sono conseguenti. Inoltre, il repentino sviluppo della costituente emotiva ha posto ulteriormente in condizione di non indugiare a credere che una macchina sarebbe stata in grado di eguagliare l’essere umano nelle sue caratteristiche intrinseche e abilità intellettive, e che l’avrebbe presto escluso dalla presa di decisione, criticità da non sottovalutare. Il via anche ad un problema di sicurezza in difesa dei dati personali utilizzati: quali sono? In che modo sono impiegati? A che scopo? Domande che non sempre trovano dichiarazioni chiare e trasparenti. Si prenda ad esempio il modello COMPAS, sviluppato privatamente per l’intercetto del crimine e del suo potenziale rischio, utilizzato attualmente dal Dipartimento Penitenziario del Wisconsin (Stati Uniti) da cui è trapelata una componente di discriminazione non indifferente, seguita dalla scarsa trasparenza dei criteri di tali valutazioni discriminanti. 
Si è reso doveroso il recupero di una definizione condivisa di Intelligenza Artificiale per avere chiaro il percorso da seguire: *“[…] una tecnologia incredibilmente promettente che può aiutarci a rendere il mondo più smart, più sano e più prospero a patto che, fin dall’inizio, sia sviluppata secondo interessi e valori umani.”* Sulle basi delle parole di John Kelly III, vicepresidente di IBM - International Business Machines Corporation, a Roma è stato firmato il Rome Call for AI Ethics, manifesto volto a stabilire e fissare delle norme etiche concernenti l’utilizzo dell’intelligenza artificiale. Lo scenario del Manifesto datato 28 febbraio 2020 si esprime senz'altro sulla centralità dell’uomo e dell’ambiente in cui vive, vedendo sì nell’A.I. un ingegnoso strumento del progresso, ma soprattutto di tutela indirizzato a conservare la libertà e la dignità umana. Nel Manifesto sono riportate alcune linee guida a cui attenersi: *trasparenza*, affinché siano chiari a tutti i fattori dell’esigenza di progettazione di determinati sistemi; *inclusione* – farsi portavoce delle occorrenze collettive, per tutti allo stesso modo; *responsabilità* – non perdere mai di vista durante tutta la fase di preparazione e realizzazione degli impianti di A.I. che si sta avendo a che fare con questioni molto serie; *obiettività*, perché è importante agire in maniera giusta ed oggettiva; *garanzia*, creare una situazione di stabilità e sicurezza; *privacy* – gli utenti hanno pieno diritto al rispetto dei propri dati personali. Firmato da una serie di personalità cruciali quali il presidente della Pontificia Accademia per la Vita Vincenzo Paglia, il direttore generale della Fao Dongyu Qu, il presidente di Microsoft Brad Smith, il ministro per l’innovazione tecnologica Paola Pisano e il sopracitato John Kelly III, il Rome Call for AI Ethics si è concluso con i sei punti riassuntivi che cercassero di far convergere tutte le questioni e problematiche fondamentali a proposito dell’Intelligenza Artificiale.

Il *Rome Call For AI Ethics* è stato quindi firmato trovando in accordo tutti gli esponenti chiamati a rappresentanti; basterà a dissolvere gli spettri dietro agli algoritmi di intelligenza artificiale, valorizzando lo sviluppo collettivo?

{{< figure library="true" src="IA3.jpg" title="" lightbox="true" >}}


**Fonti**:

1. Delogu C. [2007], Tecnologie per il web learning – realtà e scenari, Firenze, Firenze University Press.

2. Fabiano G. [2020], Regole etiche per l’Intelligenza Artificiale, https://magazine.impactscool.com/robotica-e-ai/regole-etiche-per-lintelligenza-artificiale/

3. Fonsi A. [2019], Intelligenza artificiale e tutela dei dati personali alla luce del GDPR, https://www.iusinitinere.it/intelligenza-artificiale-e-tutela-dei-dati-personali-alla-luce-del-gdpr-18455

4. Ippolita [2017], Tecnologie del dominio, Milano, Meltemi Editore.

5. Magno Caldognetto E., Cavicchio F., Cosi P., D’Urso V., Poggi I. [2008], Le emozioni e la motivazione all’apprendimento nell’e-learning: interfacce a confronto, Firenze, Firenze University Press.

6. Malcangi M. [2013], Comunicare con le emozioni, https://www.elettronicanews.it/comunicare-con-le-emozioni/

7. Mannucci L. [2020], Il Vaticano a favore dell’Intelligenza Artificiale, https://www.startingfinance.com/news/vaticano-intelligenza-artificiale/

8. MARKET BUSINESS NEWS, Kansei engineering – definition and meaning, https://marketbusinessnews.com/financial-glossary/kansei-engineering/

9. MEDIAMENTE - RAI EDUCATIONAL [1998], Il pc che riconosce il piacere e il dolore, https://www.repubblica.it/online/internet/mediamente/picard1/picard1.html

10. Numerico T., Fiormonte D. Tomasi F. [2010], L’umanista digitale, Bologna, Il Mulino.

11. Pedreschi D., Giannotti F., Guidotti R., Monreale A., Pappalardo L., Ruggieri S., Turini F. [2018], Open the Black Box, Data-Driven Explanation of Black Box Decision Systems, University of Pisa, arXiv – Cornell University.
Picard R. [1999], Affective Computing for HCI, Cambridge, Citeseerx, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.9493&rep=rep1&type=pdf
Poggi I. [2006], Le Parole del Corpo, Roma, Carocci Editore.

12. Rome Call for AI Ethics [2020], Città del Vaticano, http://www.academyforlife.va/content/dam/pav/documenti%20pdf/2020/CALL%2028%20febbraio/AI%20Rome%20Call%20x%20firma_DEF_DEF_.pdf

13. Salamini G. [2019], Intelligenza artificiale ed emozioni. Cosa ci riserva il futuro, https://www.energee3.com/blog/intelligenza-artificiale-emozioni/

14. Schütte S., Eklund J., Axelsson J.R.C., Nagamachi M. [2004], Concepts, methods and tools in Kansei Engineering, Hiroshima International University, per Theoretical Issues in Ergonomics Science, Taylor & Francis Online.

15. Simonetta F. [2018], Le emozioni dei computer: a che punto siamo e dove andiamo, https://www.techeconomy2030.it/2018/10/02/emozioni-computer-a-che-punto-siamo-e-dove-andiamo/

16. Tashea J. [2017], Courts Are Using AI to Sentence Criminals. That Must Stop Now, https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/

17. University Of Vermont [2019], AI can detect depression in a child’s speech, https://tectales.com/ai/ai-can-detect-depression-in-a-child-s-speech.html

18. Zanichelli G. [2019], Perché l’intelligenza emotiva è più importante delle competenze tecniche, https://youmanist.it/categories/storie-di-business/intelligenza-emotiva

19. Immagine: http://www.wilditaly.net/her-lamore-impossibile-spike-jonze-34871

---
